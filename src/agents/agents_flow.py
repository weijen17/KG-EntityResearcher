
from typing import TypedDict, Annotated, Literal
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_community.utilities import GoogleSerperAPIWrapper
import operator
import os
from langchain.chat_models import init_chat_model
from datetime import datetime
from pydantic import BaseModel, Field
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
from langchain.prompts import ChatPromptTemplate
from typing import Dict, List

from src.config.settings import settings

class TopicData(BaseModel):
    """äºŒçº§æ ‡ç­¾æ•°æ®æ¨¡åž‹"""
    entity_level2: str = Field(description="äºŒçº§æ ‡ç­¾")
    keywords: List[str] = Field(description="å…³é”®è¯åˆ—è¡¨")

class KGResult(BaseModel):
    """æœç´¢ç»“æžœçš„å®Œæ•´æ¨¡åž‹"""
    results: Dict[str, List[TopicData]] = Field(
        default={},
        description="ä»¥ä¸€çº§æ ‡ç­¾ä¸ºé”®ï¼ŒäºŒçº§æ ‡ç­¾(entity_level2)æ•°æ®åˆ—è¡¨ä¸ºå€¼",
        example={
            "æŠ—è€æŠ—è¡°": [
                {"entity_level2": "æŠ—æ°§åŒ–", "keywords": ["æŠ—æ°§", "åŽ»æ°§åŒ–", "æŠµå¾¡æ°§åŒ–"]},
                {"entity_level2": "æŠ—è€", "keywords": ["æŠ—è¡°è€", "å»¶ç¼“è¡°è€", "é€†é¾„"]},
                {"entity_level2": "æŠ—ç³–åŒ–", "keywords": ["æŠ—ç³–", "é˜²ç³–åŒ–", "æŠ—AGEs"]}
            ],
            "ç¾Žç™½æäº®": [
                {"entity_level2": "ç¾Žç™½æ·¡æ–‘", "keywords": ["ç¾Žç™½", "ç¾Žç™½ç„•äº®", "å˜çš„ç™½å«©"]},
                {"entity_level2": "æäº®è‚¤è‰²", "keywords": ["æäº®", "äº®è‚¤", "ç„•äº®"]}
            ]
        }
    )

class AnalystResponseFormatter(BaseModel):
    """Always use this tool to structure your response to the user."""
    next_action: Literal["[FINAL_RESULT]", "[REQUEST_MORE_INFO]"] = Field(
        description="ä¸‹ä¸€æ­¥ã€‚å¦‚æžœä¸éœ€è¦è¡¥å……ä¿¡æ¯äº†ï¼Œå°±è¿”å›ž[FINAL_RESULT]ã€‚å¦‚æžœéœ€è¦è¡¥å……ä¿¡æ¯ï¼Œè¿”å›ž[REQUEST_MORE_INFO]"
    )
    additional_info: str = Field(description="å¦‚æžœéœ€è¦è¡¥å……ä¿¡æ¯[REQUEST_MORE_INFO]ï¼Œåˆ—å‡ºéœ€è¦è¡¥å……çš„ä¿¡æ¯æˆ–æŸ¥è¯¢æ–¹å‘")
    result: KGResult = Field(description="å®žä½“ä¸€äºŒçº§æ ‡ç­¾ä½“ç³»ç»“æžœ")

parser = PydanticOutputParser(pydantic_object=AnalystResponseFormatter)
format_inst=parser.get_format_instructions()

# Define the shared state
class AgentState(TypedDict):
    industry: str
    subject: str
    query: Annotated[list, operator.add]
    messages: Annotated[list, operator.add]
    research_data: Annotated[list, operator.add]
    final_result: str
    next_agent: str
    iteration_count: int


# Initialize the LLM and Serper search tool
llm = init_chat_model(model=settings.MODEL_NAME, model_provider=settings.MODEL_PROVIDER, temperature=settings.TEMPERATURE)
llm2 = init_chat_model(model=settings.MODEL_NAME, model_provider=settings.MODEL_PROVIDER, temperature=settings.TEMPERATURE)
search = GoogleSerperAPIWrapper(k=10)

def perform_search(query: str) -> str:
    """
    Perform a web search using Serper API
    """
    try:
        results = search.results(query)

        # Extract relevant information
        search_results = []

        # Add organic results
        if "organic" in results:
            for i, result in enumerate(results["organic"][:5], 1):
                search_results.append(f"""Result {i}:
                Title: {result.get('title', 'N/A')}
                Link: {result.get('link', 'N/A')}
                Snippet: {result.get('snippet', 'N/A')}""")

        # Add knowledge graph if available
        if "knowledgeGraph" in results:
            kg = results["knowledgeGraph"]
            search_results.append(f"""Knowledge Graph:
            Title: {kg.get('title', 'N/A')}
            Description: {kg.get('description', 'N/A')}""")

        # Add answer box if available
        if "answerBox" in results:
            ab = results["answerBox"]
            search_results.append(f"""
            Answer Box:{ab.get('answer', ab.get('snippet', 'N/A'))}""")

        return "\n".join(search_results) if search_results else "No results found"

    except Exception as e:
        return f"Search error: {str(e)}"


def researcher_node(state: AgentState) -> AgentState:
    """
    Researcher agent that performs searches using Serper API
    """
    print("\nðŸ” RESEARCHER AGENT ACTIVE")

    # Get the last message to understand what to research
    messages = state.get("messages", [])
    subject = state.get("subject", "")
    industry = state.get("industry", "")
    previous_query = state.get("query", "")
    previous_result = state.get("final_result", "")
    if len(previous_result)>=1:
        previous_result=previous_result[-1]

    system_prompt1 = f'''
        ## è§’è‰²ï¼š
        ä½ æ˜¯ä¸€ä½å–„ç”¨æœç´¢å·¥å…·çš„ç ”ç©¶å‘˜ã€‚ä½ éœ€è¦æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯è¿›è¡Œæ”¹å†™å’Œè°ƒæ•´ï¼Œå¹¶ç”¨è¿™è°ƒæ•´å¥½çš„ä¿¡æ¯è¿›è¡ŒæŸ¥è¯¢ã€‚
        
        ## ä»»åŠ¡ï¼š
        ä½ æ˜¯ã€{industry}ã€‘è¡Œä¸šä¸“å®¶ï¼Œç›®å‰åœ¨æ•´åˆç½‘ç»œä¸Šç”¨æˆ·å¯èƒ½æåˆ°çš„å„ç§å®žä½“ã€{subject}ã€‘çš„ä¸€äºŒçº§æ ‡ç­¾ä½“ç³»ã€‚è¯·é’ˆå¯¹ã€{industry}ã€‘è¡Œä¸šçš„å®žä½“ã€{subject}ã€‘ï¼Œç¼–å†™æœç´¢æŸ¥è¯¢å¥å­ã€‚
        
        ## åŽŸåˆ™ï¼š
        åªè¿”å›žæœç´¢æŸ¥è¯¢å¥å­ï¼Œåˆ«çš„éƒ½ä¸è¦ã€‚'''

    response = llm.invoke([SystemMessage(content=system_prompt1)])

    query_content = response.content
    last_message_content = 'è¿˜æ²¡åé¦ˆ'
    # Determine search query
    if not messages or len(messages) == 0:
        # Initial research
        search_query = query_content
        print(f"ç¬¬ä¸€ä¸ªæŸ¥è¯¢: {search_query}")
    else:
        # Follow-up research based on analyst's request
        last_message = messages[-1]
        last_message_content = last_message.content

        # Use LLM to extract specific search query from analyst's request
        query_prompt = f"""
        ## è§’è‰²ï¼š
        ä½ æ˜¯ä¸€ä½å–„ç”¨æœç´¢å·¥å…·çš„ç ”ç©¶å‘˜ã€‚
        
        ## ä»»åŠ¡ï¼š
        ä½ æ˜¯ã€{industry}ã€‘è¡Œä¸šä¸“å®¶ï¼Œç›®å‰åœ¨æ•´åˆç½‘ç»œä¸Šç”¨æˆ·å¯èƒ½æåˆ°çš„å„ç§å®žä½“ã€{subject}ã€‘çš„ä¸€äºŒçº§æ ‡ç­¾ä½“ç³»ã€‚ä½ ä¼šé’ˆå¯¹ã€{industry}ã€‘è¡Œä¸šçš„å®žä½“ã€{subject}ã€‘ï¼Œç¼–å†™æœç´¢æŸ¥è¯¢å¥å­ã€‚
        æ ¹æ®åˆ†æžå¸ˆçš„éœ€æ±‚åé¦ˆï¼Œè¯·å†ç”Ÿæˆ1ä¸ªç²¾ç®€çš„ç½‘ç»œæœç´¢æŸ¥è¯¢å¥å­ã€‚ç¡®ä¿æœç´¢æŸ¥è¯¢å¥å­çš„å­—æ•°ä¸è¶…è¿‡50ä¸ªå­—.
        
        åˆ†æžå¸ˆåé¦ˆ: {last_message_content}
        åˆ†æžå¸ˆç›®å‰å·²æ•´åˆå¥½çš„æ ‡ç­¾ä½“ç³»: {previous_result}
        ç›®æ ‡è¡Œä¸š: {industry}
        ç›®æ ‡å®žä½“: {subject}
        ä¹‹å‰ä½ ç”¨è¿‡çš„æœç´¢æŸ¥è¯¢å¥å­ï¼š{previous_query}
        
        ## åŽŸåˆ™ï¼š
        1ã€åªè¿”å›žæœç´¢æŸ¥è¯¢å¥å­ï¼Œåˆ«çš„éƒ½ä¸è¦ã€‚
        2ã€é¿å…ä½¿ç”¨ä¹‹å‰ä½ ç”¨è¿‡çš„æœç´¢æŸ¥è¯¢å¥å­ã€‚æœç´¢æŸ¥è¯¢å¥å­å°½é‡å’Œä¹‹å‰çš„ä¸ä¸€æ ·ã€‚"""

        query_response = llm.invoke([SystemMessage(content=system_prompt1),
                                     HumanMessage(content=query_prompt)])
        search_query = query_response.content.strip()
        print(f"Follow-up search query: {search_query}")

    # Perform actual web search using Serper
    print(f"Searching web for: {search_query}")
    search_results = perform_search(search_query)

    system_prompt2 = f'''
            ## è§’è‰²ï¼š
            ä½ æ˜¯ä¸€ä½å¸‚åœºè°ƒç ”ä¸“å®¶å’Œã€{industry}ã€‘è¡Œä¸šä¸“å®¶ï¼Œç›®å‰åœ¨æ•´åˆç½‘ç»œä¸Šç”¨æˆ·å¯èƒ½æåˆ°çš„å„ç§å®žä½“ã€{subject}ã€‘çš„ä¸€äºŒçº§æ ‡ç­¾ä½“ç³»ã€‚

            ## ä»»åŠ¡ï¼š
            1ã€æ ¹æ®æœç´¢æŸ¥è¯¢å›žæ¥çš„ä¿¡æ¯ï¼Œä½ çš„ä»»åŠ¡æ˜¯æŠŠæ‰€æœ‰å¯èƒ½çš„ã€{industry}ã€‘è¡Œä¸šçš„å®žä½“ã€{subject}ã€‘å…³é”®è¯éƒ½å…¨éƒ¨åˆ—å‡ºæ¥ã€‚
            2ã€å°è¯•å¯¹æ¯ä¸ªå®žä½“ã€{subject}ã€‘è¿›è¡Œå½’ç±»ï¼Œæ¯ä¸ªç±»ä¸‹ä¹Ÿåˆ—å‡ºå¯¹åº”çš„å…³é”®è¯ã€‚ç¡®ä¿æ¯ä¸ªç±»æ˜¯äº’æ–¥çš„ã€‚'''

    # Have LLM synthesize the search results
    synthesis_prompt = f"""è¯·æ ¹æ®ç½‘ç»œæœç´¢ç»“æžœå’Œåˆ†æžå¸ˆåé¦ˆï¼ŒæŠŠæ‰€æœ‰å¯èƒ½çš„ã€{industry}ã€‘è¡Œä¸šçš„ã€{subject}ã€‘éƒ½å…¨éƒ¨åˆ—å‡ºæ¥ã€‚å°è¯•å¯¹æ¯ä¸ªå®žä½“ã€{subject}ã€‘è¿›è¡Œå½’ç±»ï¼Œæ¯ä¸ªç±»ä¸‹ä¹Ÿåˆ—å‡ºå¯¹åº”çš„å…³é”®è¯ã€‚ç¡®ä¿æ¯ä¸ªç±»æ˜¯äº’æ–¥çš„ã€‚
    
    åˆ†æžå¸ˆåé¦ˆï¼š{last_message_content}
    åˆ†æžå¸ˆç›®å‰å·²æ•´åˆå¥½çš„æ ‡ç­¾ä½“ç³»: {previous_result}
    ç›®æ ‡è¡Œä¸šï¼š{industry}
    ç›®æ ‡å®žä½“ï¼š{subject}
    æœç´¢æŸ¥è¯¢å¥å­ï¼š{search_query}
    æœç´¢æŸ¥è¯¢ç»“æžœï¼š{search_results}"""

    response = llm.invoke([
        SystemMessage(content=system_prompt2),
        HumanMessage(content=synthesis_prompt)
    ])

    research_content = response.content
    print(f"æœç´¢åŽçš„ä¿¡æ¯æ€»ç»“: {research_content[:400]}...")

    return {
        "research_data": [research_content],
        "query":[query_content],
        "messages": [AIMessage(content=f"[RESEARCHER]: {research_content}", name="researcher")],
        "next_agent": "analyst"
    }

def analyst_node(state: AgentState) -> AgentState:
    """
    Analyst agent that reviews research and writes reports or requests more info
    """
    print("\nðŸ“Š ANALYST AGENT ACTIVE")

    research_data = state.get("research_data", [])
    subject = state.get("subject", "")
    industry = state.get("industry", "")
    iteration = state.get("iteration_count", 0)
    previous_result = state.get("final_result", "")
    if len(previous_result) >= 1:
        previous_result = previous_result[-1]

    system_prompt = f'''
    ## è§’è‰²ï¼š
    ä½ æ˜¯{industry}è¡Œä¸šä¸“å®¶ï¼Œç›®å‰åœ¨æ•´åˆå’Œæ‰©å±•ã€{industry}ã€‘è¡Œä¸šçš„å…³äºŽå®žä½“ã€{subject}ã€‘çš„æ ‡ç­¾ä½“ç³»ã€‚æ­å»ºæ—¶ä¼šè€ƒè™‘ä»¥ä¸‹è¿™ä¸¤ç‚¹ï¼š
    1ã€è¿™äº›æ ‡ç­¾å¯¹{industry}çš„å®¢æˆ·æ˜¯éžå¸¸é‡è¦çš„ã€‚å®¢æˆ·ä¼šç”¨è¿™äº›æ ‡ç­¾æ¥è¿›è¡Œåˆ†æžã€ç ”å‘æ–°{industry}äº§å“å’Œå®šä½{subject}çš„äººç¾¤ã€‚
    2ã€åœ¨{industry}çš„å“ç‰Œå®¢æˆ·çš„å…¬å¸ï¼Œæ¯ä¸ªéƒ¨é—¨éƒ½è´Ÿè´£å„è‡ªäº§å“å’Œä¸€ä¸ªç»†åˆ†{subject}æ ‡ç­¾ã€‚æ‰€ä»¥ï¼Œæ¯ä¸ªäºŒçº§æ ‡ç­¾é¢—ç²’åº¦éœ€è¦è¶³å¤Ÿç»†ï¼ˆä½†ä¹Ÿè¦æœ‰ä¸€å®šçš„è®¨è®ºé‡ï¼Œä¸”èƒ½å‡ºinsight)ï¼Œä¹Ÿéœ€è¦ç¡®ä¿"ä¸€çº§å’Œä¸€çº§"æˆ–"äºŒçº§å’ŒäºŒçº§"ä¹‹é—´æ˜¯äº’æ–¥çš„ã€‚
    
    ## ä»»åŠ¡ï¼š
    1ã€ä½ ä¼šå…ˆæ­å»ºä¸€ç‰ˆå«ä¸€çº§äºŒçº§çš„æ ‡ç­¾ä½“ç³»æ¡†æž¶å‡ºæ¥ã€‚åŒæ—¶ä¹Ÿåˆ—å‡ºæ¯ä¸ªäºŒçº§æ ‡ç­¾ä¸‹å¯èƒ½çš„å…³é”®è¯ã€‚
    2ã€å¦‚æžœã€ä½ ä¸Šä¸€æ¬¡æ•´åˆå¥½çš„æ ‡ç­¾ä½“ç³»ã€‘é‡Œæœ‰æ•°æ®ï¼Œä½ å¯ä»¥æ ¹æ®è¿™ä¸ªä¿¡æ¯è¿›è¡Œæ ‡ç­¾ä½“ç³»æ¡†æž¶çš„è¿­ä»£ã€‚
    3ã€ç„¶åŽï¼Œæ ¹æ®ã€æŸ¥è¯¢ç ”ç©¶ä»£ç†ã€‘çš„ç½‘ç»œæœç´¢ç»“æžœï¼Œä½ å†ä¸€æ¬¡è¿›è¡Œæ ‡ç­¾ä½“ç³»æ¡†æž¶çš„æ•´åˆå’Œæ‰©å±•ã€‚
    4ã€å¦‚æžœä¿¡æ¯ä¸å¤Ÿï¼Œä½ éœ€è¦åé¦ˆç»™ã€æŸ¥è¯¢ç ”ç©¶ä»£ç†ã€‘ï¼Œè®©ä»–æŒ‰ç…§ä½ çš„åé¦ˆè¿›è¡Œä¸‹ä¸€æ­¥æŸ¥è¯¢ï¼Œä»¥è¡¥å…¨ä¿¡æ¯ã€‚
    5ã€ç¡®ä¿æ¯ä¸ªä¸€çº§æ ‡ç­¾ä¹‹é—´æ˜¯äº’æ–¥çš„ï¼Œå’Œç¡®ä¿æ¯ä¸ªäºŒçº§æ ‡ç­¾ä¹‹é—´ä¹Ÿæ˜¯äº’æ–¥çš„
    
    ç›®æ ‡è¡Œä¸šï¼š{industry}
    ç›®æ ‡å®žä½“ï¼š{subject}
    ç›®å‰æŸ¥è¯¢æ¬¡æ•°ï¼š{iteration}
    ä½ ä¸Šä¸€æ¬¡æ•´åˆå¥½çš„æ ‡ç­¾ä½“ç³»ï¼š{previous_result}
    
    ## è¾“å‡ºæ ¼å¼ï¼š
    {format_inst}
    
    ## åŽŸåˆ™ï¼š
    1ã€æŒ‰ç…§ä»¥ä¸Šçš„jsonæ ¼å¼è¾“å‡ºã€‚
    2ã€è¯·ç¡®ä¿æœ€ç»ˆæ ‡ç­¾æœ‰5ä¸ªä¸€çº§å®žä½“æ ‡ç­¾ï¼Œæ¯ä¸ªä¸€çº§å®žä½“æ ‡ç­¾ä¸‹æœ‰èµ·ç 3ä¸ªäºŒçº§å®žä½“æ ‡ç­¾ã€‚å¦‚æžœä¸æ»¡è¶³è¿™ä¸ªæ¡ä»¶ï¼Œè¯·æŒ‰ä¸Šè¿°çš„jsonæ ¼å¼è¾“å‡º[REQUEST_MORE_INFO]ï¼Œå¹¶åœ¨additional_infoé‡Œæå‡ºéœ€è¦è¿›ä¸€æ­¥çš„æŸ¥è¯¢æ–¹å‘ã€‚
    3ã€å¦‚æžœä¸Šé¢çš„éœ€æ±‚æ»¡è¶³äº†ï¼Œè¯·è¾“å‡º[FINAL_RESULT]ï¼Œå’ŒæŒ‰ä»¥ä¸Šæåˆ°çš„â€è¾“å‡ºæ ¼å¼"è¾“å‡ºæ•´ä¸ªæ ‡ç­¾ä½“ç³»ã€‚
    4ã€è¯·ç¡®ä¿æœ‰è‡³å°‘2æ¬¡çš„æŸ¥è¯¢æ¬¡æ•°ã€‚
    5ã€è¯·ä¿æŒåˆç†çš„æŸ¥è¯¢æ¬¡æ•°ã€‚å¦‚æžœæŸ¥è¯¢æ¬¡æ•°å·²ç»è¶…è¿‡äº†5ï¼Œè¯·è¾“å‡º[FINAL_RESULT]ï¼Œå¹¶ä¾¿ç”¨çŽ°æœ‰çš„ã€æŸ¥è¯¢ç ”ç©¶ä»£ç†ã€‘ç½‘ç»œæœç´¢ç»“æžœæ•°æ®è¾“å‡ºä¸€ä¸ªå®Œæ•´çš„åå­—å’Œé“¾æŽ¥åˆ—è¡¨ã€‚
    '''

    chat_prompt = ChatPromptTemplate.from_messages([SystemMessage(content=system_prompt),
                                                    AIMessage(content=f'## ã€æŸ¥è¯¢ç ”ç©¶ä»£ç†ã€‘ç½‘ç»œæœç´¢ç»“æžœæ•°æ® å¦‚ä¸‹ï¼š\n\n{research_data}')])
    chain = chat_prompt | llm2 | parser

    analyst_response = chain.invoke({})
    next_action = analyst_response.model_dump().get('next_action')
    additional_info = analyst_response.model_dump().get('additional_info')
    result = analyst_response.model_dump().get('result')

    print(f"åˆ†æžå¸ˆæ€»ç»“: {next_action}\n\n{additional_info}\n\n{result}...")

    # Check if analyst wants more info or is ready to report
    if next_action == "[FINAL_RESULT]" or iteration >= 5:
        # Extract report (remove the [FINAL REPORT] marker if present)
        return {
            "final_result": result,
            "messages": [AIMessage(content=f"[ANALYST]: {result}", name="analyst")],
            "next_agent": "end",
            "iteration_count": iteration + 1
        }
    else:
        # Analyst needs more info
        return {
            "final_result": result,
            "messages": [AIMessage(content=additional_info, name="analyst")],
            "next_agent": "researcher",
            "iteration_count": iteration + 1
        }


def route_agent(state: AgentState) -> Literal["researcher", "analyst", "end"]:
    """
    Route to the next agent based on state
    """
    next_agent = state.get("next_agent", "researcher")
    #
    # if next_agent == "end":
    #     return END
    return next_agent


# Build the graph
def create_research_graph():
    workflow = StateGraph(AgentState)

    # Add nodes
    workflow.add_node("researcher", researcher_node)
    workflow.add_node("analyst", analyst_node)

    # Set entry point
    workflow.set_entry_point("researcher")

    # Add conditional edges
    workflow.add_conditional_edges(
        "researcher",
        route_agent,
        {
            "analyst": "analyst",
            "end": END
        }
    )

    workflow.add_conditional_edges(
        "analyst",
        route_agent,
        {
            "researcher": "researcher",
            "end": END
        }
    )

    return workflow.compile()


class run_research_report():
    def run(self,subject: str,industry: str):
        """
        Run the two-agent system to research and report on a subject
        """
        print(f"\n{'=' * 60}")
        print(f"Starting Name Research on industry ({industry}) - subject ({subject})")
        print(f"{'=' * 60}")

        graph = create_research_graph()

        initial_state = {
            "industry": industry,
            "subject": subject,
            "messages": [],
            "research_data": [],
            "final_result": "",
            "next_agent": "researcher",
            "iteration_count": 0
        }

        # Run the graph
        final_state = graph.invoke(initial_state)

        print(f"\n{'=' * 60}")
        print("FINAL RESULT")
        print(f"{'=' * 60}")
        print(final_state["final_result"])
        print(f"\n{'=' * 60}")

        return final_state

    def _save_result(self, subject: str, industry: str, result: str):
        """Save the report to a file"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{industry}_{subject}_result_{timestamp}.txt"
        filepath = settings.OUTPUT_DIR / filename
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"SUBJECT: {subject}\n")
            f.write(f"INDUSTRY: {industry}\n")
            f.write(f"DATE: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"\n{'=' * 70}\n\n")
            f.write(result)
        print(f"âœ… Result saved to: {filepath}")

    def _save_research_result(self, subject: str, industry: str, result: str):
        """Save the report to a file"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{industry}_{subject}_research_result_{timestamp}.txt"
        filepath = settings.OUTPUT_DIR / filename
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"SUBJECT: {subject}\n")
            f.write(f"INDUSTRY: {industry}\n")
            f.write(f"DATE: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"\n{'=' * 70}\n\n")
            f.write(result)
        print(f"âœ… Result saved to: {filepath}")

